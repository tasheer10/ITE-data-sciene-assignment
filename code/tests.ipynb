{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.data import find\n",
    "from matching_model.utils import (\n",
    "        clean_text,\n",
    "        get_visitor_interests,\n",
    "        get_exhibitor_category_info,\n",
    "        calculate_match_score\n",
    "    )\n",
    "import ipytest \n",
    "# Configure ipytest to discover tests and manage fixtures in the notebook\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_nltk_resources():\n",
    "    resources = ['corpora/wordnet', 'corpora/stopwords']\n",
    "    downloaded = False\n",
    "    for resource in resources:\n",
    "        try:\n",
    "            find(resource)\n",
    "        except LookupError:\n",
    "            resource_name = resource.split('/')[-1]\n",
    "            print(f\"NLTK resource '{resource_name}' not found. Downloading...\")\n",
    "            try:\n",
    "                nltk.download(resource_name, quiet=True)\n",
    "                print(f\"Successfully downloaded '{resource_name}'.\")\n",
    "                downloaded = True\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading NLTK resource '{resource_name}': {e}\")\n",
    "    if downloaded:\n",
    "        print(\"NLTK setup complete.\")\n",
    "\n",
    "ensure_nltk_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Variables / Constants ---\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "RELEVANT_QUESTIONS_TEST = [\n",
    "    \"Please indicate your company's main area of business\",\n",
    "    \"Which of the following best describes your job function?\"\n",
    "]\n",
    "PENALTY_ALPHA_TEST = 0.5\n",
    "PENALTY_THRESHOLD_TEST = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fixtures for Mock Data ---\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def mock_visitor_data():\n",
    "    \"\"\"Provides the mock visitor DataFrame.\"\"\"\n",
    "    visitor_data = {\n",
    "        'visitor_id': ['v1', 'v1', 'v1', 'v2', 'v2', 'v3', 'v4'],\n",
    "        'visitor_email': ['v1@test.com', 'v1@test.com', 'v1@test.com', 'v2@test.com', 'v2@test.com', 'v3@test.com', 'v4@test.com'],\n",
    "        'questionText': [\n",
    "            RELEVANT_QUESTIONS_TEST[0], # Relevant\n",
    "            RELEVANT_QUESTIONS_TEST[1], # Relevant\n",
    "            'Irrelevant Question',      # Irrelevant\n",
    "            RELEVANT_QUESTIONS_TEST[0], # Relevant\n",
    "            'Another Irrelevant',       # Irrelevant\n",
    "            'Another1 Irrelevant',          # Irrelevant\n",
    "            RELEVANT_QUESTIONS_TEST[1], # Relevant\n",
    "        ],\n",
    "        'answerText': [\n",
    "            'Travel Agent',\n",
    "            'Marketing and Sales',\n",
    "            'Blue',\n",
    "            'Tour Operator',\n",
    "            'Yes',\n",
    "            'Maybe',\n",
    "            'Media',\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(visitor_data)\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def mock_exhibitor_data():\n",
    "    \"\"\"Provides the mock exhibitor DataFrame.\"\"\"\n",
    "    exhibitor_data = {\n",
    "        'exhibitorid': [101, 101, 101, 102, 102, 104, 104, 104, 104, 104, 104, 104],\n",
    "        'exhibitorName': ['Exhibitor A', 'Exhibitor A', 'Exhibitor A', 'Exhibitor B', 'Exhibitor B', 'Exhibitor D', 'Exhibitor D', 'Exhibitor D', 'Exhibitor D', 'Exhibitor D', 'Exhibitor D', 'Exhibitor D'],\n",
    "        'categoryId': [500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512],\n",
    "        'categoryName': [\n",
    "            '3.1 Travel Agency',\n",
    "            '4.1 Online Marketing',\n",
    "            '5.1 Sales Support',\n",
    "            '2.1 Tour Operators',\n",
    "            '1.1 Hotels and Resorts',\n",
    "            '1.1 Hotels',\n",
    "            '2.1 Tour Op',\n",
    "            '3.1 Agency',\n",
    "            '4.1 Online Ads',\n",
    "            '5.1 Support',\n",
    "            '6.1 Cruises',\n",
    "            '7.1 Niche Travel'\n",
    "        ],\n",
    "        'parentCategory': [\n",
    "            '3. Travel Agencies',\n",
    "            '4. Marketing',\n",
    "            '5. Sales',\n",
    "            '2. Tour Operators',\n",
    "            '1. Accommodation',\n",
    "            '1. Accommodation',\n",
    "            '2. Tour Operators',\n",
    "            '3. Travel Agencies',\n",
    "            '4. Marketing',\n",
    "            '5. Sales',\n",
    "            '6. Cruises',\n",
    "            '7. Niche'\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(exhibitor_data)\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def processed_exhibitor_data(mock_exhibitor_data):\n",
    "    \"\"\"Processes the mock exhibitor data once per module.\"\"\"\n",
    "    return get_exhibitor_category_info(mock_exhibitor_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clean_text():\n",
    "    assert clean_text(\" 1.1 Hotels and Resorts \") == \"hotels resorts\"\n",
    "    assert clean_text(\"Travel & Agency!\") == \"travel agency\"\n",
    "    assert clean_text(\"Marketing and Sales Support\") == \"marketing sales support\"\n",
    "    assert clean_text(\"This is a stop word test\") == \"stop word test\"\n",
    "    assert clean_text(\"10.5 Zoo\") == \"zoo\"\n",
    "    assert clean_text(\"17.3 Banking, investments\") == \"banking investments\"\n",
    "    assert clean_text(\"  \") == \"\"\n",
    "    assert clean_text(None) == \"\"\n",
    "    assert clean_text(123) == \"\"\n",
    "    assert clean_text(\"3. Travel  agencies\") == \"travel agencies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_visitor_interests(mock_visitor_data):\n",
    "    # Visitor 1: Travel Agent, Marketing and Sales\n",
    "    expected_v1 = {'travel', 'agent', 'travel agent', 'marketing', 'sales', 'marketing sales'}\n",
    "    expected_v1.add(lemmatizer.lemmatize('agent'))\n",
    "    expected_v1.add(lemmatizer.lemmatize('marketing'))\n",
    "    expected_v1.add(lemmatizer.lemmatize('sales'))\n",
    "    assert get_visitor_interests('v1@test.com', mock_visitor_data, RELEVANT_QUESTIONS_TEST) == expected_v1\n",
    "\n",
    "    # Visitor 2: Tour Operator\n",
    "    expected_v2 = {'tour', 'operator', 'tour operator'}\n",
    "    expected_v2.add(lemmatizer.lemmatize('operator'))\n",
    "    assert get_visitor_interests('v2@test.com', mock_visitor_data, RELEVANT_QUESTIONS_TEST) == expected_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_exhibitor_category_info(processed_exhibitor_data):\n",
    "    exhibitor_categories_map, exhibitor_category_counts = processed_exhibitor_data\n",
    "\n",
    "    # Exhibitor 101: Travel Agency, Online Marketing, Sales Support\n",
    "    expected_cats_101 = {'travel', 'agency', 'travel agency', 'online', 'marketing', 'online marketing', 'sales', 'support', 'sales support'}\n",
    "    expected_cats_101.add(lemmatizer.lemmatize('agency'))\n",
    "    expected_cats_101.add(lemmatizer.lemmatize('marketing'))\n",
    "    expected_cats_101.add(lemmatizer.lemmatize('sales'))\n",
    "    expected_cats_101.add(lemmatizer.lemmatize('support'))\n",
    "    assert exhibitor_categories_map[101] == expected_cats_101\n",
    "    assert exhibitor_category_counts[101] == 3 # 3 unique parent categories\n",
    "\n",
    "    # Exhibitor 102: Tour Operators, Hotels and Resorts\n",
    "    expected_cats_102 = {'tour', 'operators', 'tour operators', 'hotels', 'resorts', 'hotels resorts'}\n",
    "    expected_cats_102.add(lemmatizer.lemmatize('operators'))\n",
    "    expected_cats_102.add(lemmatizer.lemmatize('hotels'))\n",
    "    expected_cats_102.add(lemmatizer.lemmatize('resorts'))\n",
    "    expected_cats_102.add(lemmatizer.lemmatize('hotel')) # from hotels\n",
    "    expected_cats_102.add(lemmatizer.lemmatize('resort')) # from resorts\n",
    "    expected_cats_102.add(lemmatizer.lemmatize('operator')) # from operators\n",
    "    assert exhibitor_categories_map[102] == expected_cats_102\n",
    "    assert exhibitor_category_counts[102] == 2 # 2 unique parent categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calculate_match_score_no_overlap():\n",
    "    visitor = {'interest1', 'interest2'}\n",
    "    exhibitor = {'catA', 'catB'}\n",
    "    score, num, matched = calculate_match_score(visitor, exhibitor, 2, PENALTY_ALPHA_TEST, PENALTY_THRESHOLD_TEST)\n",
    "    assert score == 0.0\n",
    "    assert num == 0\n",
    "    assert matched == set()\n",
    "\n",
    "def test_calculate_match_score_partial_overlap_no_penalty():\n",
    "    visitor = {'travel', 'agent', 'hotel'}\n",
    "    exhibitor = {'travel', 'agency', 'tour'}\n",
    "    total_cats = 3 # Below threshold\n",
    "    score, num, matched = calculate_match_score(visitor, exhibitor, total_cats, PENALTY_ALPHA_TEST, PENALTY_THRESHOLD_TEST)\n",
    "    assert score == 1.0 # Score = num_matches (1) * penalty_factor (1)\n",
    "    assert num == 1\n",
    "    assert matched == {'travel'}\n",
    "\n",
    "def test_calculate_match_score_multiple_overlap_no_penalty():\n",
    "    visitor = {'travel', 'agent', 'hotel', 'resort'}\n",
    "    exhibitor = {'travel', 'agency', 'hotel', 'booking'}\n",
    "    total_cats = 4 # Below threshold\n",
    "    score, num, matched = calculate_match_score(visitor, exhibitor, total_cats, PENALTY_ALPHA_TEST, PENALTY_THRESHOLD_TEST)\n",
    "    assert score == 2.0 # Score = num_matches (2) * penalty_factor (1)\n",
    "    assert num == 2\n",
    "    assert matched == {'travel', 'hotel'}\n",
    "\n",
    "def test_calculate_match_score_with_penalty():\n",
    "    visitor = {'travel', 'agent', 'hotel', 'resort', 'op'}\n",
    "    exhibitor = {'travel', 'agency', 'hotel', 'booking', 'op'}\n",
    "    total_cats = 8 # Above threshold of 6\n",
    "    penalty_threshold = PENALTY_THRESHOLD_TEST # 6\n",
    "    penalty_alpha = PENALTY_ALPHA_TEST       # 0.5\n",
    "    expected_penalty_factor = 1.0 / (1.0 + penalty_alpha * max(0, total_cats - penalty_threshold))\n",
    "    # expected_penalty_factor = 1.0 / (1.0 + 0.5 * (8 - 6)) = 1.0 / (1.0 + 0.5 * 2) = 1.0 / 2.0 = 0.5\n",
    "    expected_score = 3 * expected_penalty_factor # 3 matches * 0.5\n",
    "\n",
    "    score, num, matched = calculate_match_score(visitor, exhibitor, total_cats, penalty_alpha, penalty_threshold)\n",
    "    assert score == pytest.approx(expected_score)\n",
    "    assert num == 3\n",
    "    assert matched == {'travel', 'hotel', 'op'}\n",
    "\n",
    "def test_calculate_match_score_at_penalty_threshold():\n",
    "    visitor = {'travel', 'agent', 'hotel'}\n",
    "    exhibitor = {'travel', 'agency', 'hotel', 'booking'}\n",
    "    total_cats = 6 # At threshold\n",
    "    penalty_threshold = PENALTY_THRESHOLD_TEST # 6\n",
    "    penalty_alpha = PENALTY_ALPHA_TEST       # 0.5\n",
    "    expected_penalty_factor = 1.0 / (1.0 + penalty_alpha * max(0, total_cats - penalty_threshold))\n",
    "    # expected_penalty_factor = 1.0 / (1.0 + 0.5 * (6 - 6)) = 1.0 / 1.0 = 1.0\n",
    "    expected_score = 2 * expected_penalty_factor # 2 matches * 1.0\n",
    "\n",
    "    score, num, matched = calculate_match_score(visitor, exhibitor, total_cats, penalty_alpha, penalty_threshold)\n",
    "    assert score == pytest.approx(expected_score)\n",
    "    assert num == 2\n",
    "    assert matched == {'travel', 'hotel'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.11.5, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: d:\\ITEProject\\ITE-data-sciene-assignment\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0\n",
      "collected 8 items\n",
      "\n",
      "t_68ab2931365e4ffca6bfa73c3a33b819.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mE\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                               [100%]\u001b[0m\n",
      "\n",
      "============================================= ERRORS ==============================================\n",
      "\u001b[31m\u001b[1m_______________________ ERROR at setup of test_get_exhibitor_category_info ________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmock_exhibitor_data\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Provides the mock exhibitor DataFrame.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        exhibitor_data = {\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mexhibitorid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[94m101\u001b[39;49;00m, \u001b[94m101\u001b[39;49;00m, \u001b[94m101\u001b[39;49;00m, \u001b[94m102\u001b[39;49;00m, \u001b[94m102\u001b[39;49;00m, \u001b[94m103\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m, \u001b[94m104\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mexhibitorName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor A\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor A\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor A\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor B\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor B\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExhibitor D\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mcategoryId\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[94m500\u001b[39;49;00m, \u001b[94m501\u001b[39;49;00m, \u001b[94m502\u001b[39;49;00m, \u001b[94m503\u001b[39;49;00m, \u001b[94m504\u001b[39;49;00m, \u001b[94m505\u001b[39;49;00m, \u001b[94m506\u001b[39;49;00m, \u001b[94m507\u001b[39;49;00m, \u001b[94m508\u001b[39;49;00m, \u001b[94m509\u001b[39;49;00m, \u001b[94m510\u001b[39;49;00m, \u001b[94m511\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mcategoryName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m3.1 Travel Agency\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m4.1 Online Marketing\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m5.1 Sales Support\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m2.1 Tour Operators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m1.1 Hotels and Resorts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m1.1 Hotels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m2.1 Tour Op\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m3.1 Agency\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m4.1 Online Ads\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m5.1 Support\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m6.1 Cruises\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m7.1 Niche Travel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mparentCategory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m3. Travel Agencies\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m4. Marketing\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m5. Sales\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m2. Tour Operators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m1. Accommodation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m1. Accommodation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m2. Tour Operators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m3. Travel Agencies\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m4. Marketing\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m5. Sales\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m6. Cruises\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33m7. Niche\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ]\u001b[90m\u001b[39;49;00m\n",
      "        }\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.DataFrame(exhibitor_data)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Tasheer\\AppData\\Local\\Temp\\ipykernel_2732\\3210639400.py\u001b[0m:66: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31m..\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m:778: in __init__\n",
      "    \u001b[0mmgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m:503: in dict_to_mgr\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m..\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m:114: in arrays_to_mgr\n",
      "    \u001b[0mindex = _extract_index(arrays)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "data = [[101, 101, 101, 102, 102, 103, ...], ['Exhibitor A', 'Exhibitor A', 'Exhibitor A', 'Exhibitor B', 'Exhibitor B', 'Exh..., ['3. Travel Agencies', '4. Marketing', '5. Sales', '2. Tour Operators', '1. Accommodation', '1. Accommodation', ...]]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_extract_index\u001b[39;49;00m(data) -> Index:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Try to infer an Index from the passed data, raise ValueError on failure.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        index: Index\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(data) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m default_index(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        raw_lengths = []\u001b[90m\u001b[39;49;00m\n",
      "        indexes: \u001b[96mlist\u001b[39;49;00m[\u001b[96mlist\u001b[39;49;00m[Hashable] | Index] = []\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        have_raw_arrays = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        have_series = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        have_dicts = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m val \u001b[95min\u001b[39;49;00m data:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(val, ABCSeries):\u001b[90m\u001b[39;49;00m\n",
      "                have_series = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                indexes.append(val.index)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(val, \u001b[96mdict\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                have_dicts = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                indexes.append(\u001b[96mlist\u001b[39;49;00m(val.keys()))\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m is_list_like(val) \u001b[95mand\u001b[39;49;00m \u001b[96mgetattr\u001b[39;49;00m(val, \u001b[33m\"\u001b[39;49;00m\u001b[33mndim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                have_raw_arrays = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                raw_lengths.append(\u001b[96mlen\u001b[39;49;00m(val))\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(val, np.ndarray) \u001b[95mand\u001b[39;49;00m val.ndim > \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mPer-column arrays must each be 1-dimensional\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m indexes \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m raw_lengths:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mIf using all scalar values, you must pass an index\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m have_series:\u001b[90m\u001b[39;49;00m\n",
      "            index = union_indexes(indexes)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m have_dicts:\u001b[90m\u001b[39;49;00m\n",
      "            index = union_indexes(indexes, sort=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m have_raw_arrays:\u001b[90m\u001b[39;49;00m\n",
      "            lengths = \u001b[96mlist\u001b[39;49;00m(\u001b[96mset\u001b[39;49;00m(raw_lengths))\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(lengths) > \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAll arrays must be of the same length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               ValueError: All arrays must be of the same length\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m..\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m:677: ValueError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m t_68ab2931365e4ffca6bfa73c3a33b819.py::\u001b[1mtest_get_exhibitor_category_info\u001b[0m - ValueError: All arrays must be of the same length\n",
      "\u001b[31m=================================== \u001b[32m7 passed\u001b[0m, \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 4.46s\u001b[0m\u001b[31m ====================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run('-v') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
